{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at reproducing the training and results for the worker object detection. It also computes the performance of the model. More specifically, we use the detecto python library to train our model (https://detecto.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import get_kwargs_xml_worker, create_xml\n",
    "from utils.performance_viz import plot_matching_bbs, get_mean_iou, plot_bbs\n",
    "from utils.performance_metrics import get_avg_precision_at_iou, plot_pr_curve, COLORS\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "from detecto import core, utils, visualize\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import xmltodict\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part assumes that we already have downloaded the images and jsons related to this project. \\\n",
    "If not, please refer to the README to download these files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON to XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories from root (here /home)\n",
    "imgs_directory = \"/home/jovyan/chronsite/Detection_Train_Set/Detection_Train_Set_Img\" \n",
    "jsons_directory = \"/home/jovyan/chronsite/Detection_Train_Set/Detection_Train_Set_Json\"\n",
    "xml_directory = \"/home/jovyan/chronsite/Detection_Train_Set/Detection_Train_Set_Xml\"\n",
    "\n",
    "imgs = glob.glob(imgs_directory + \"/*.jpg\")\n",
    "jsons = glob.glob(jsons_directory + \"/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(xml_directory)\n",
    "except FileExistsError:\n",
    "    print(\"Directory already created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_path in jsons:\n",
    "    kwgs = get_kwargs_xml_worker(json_path)\n",
    "    create_xml(xml_directory, **kwgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model, we create a training (80%) and testing (20%) dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.mkdir(\"train\")\n",
    "os.mkdir(\"test\")\n",
    "\n",
    "# Training Dataset\n",
    "tot_imgs = len(imgs)\n",
    "random.seed(41)\n",
    "train_imgs = random.sample(imgs, k=round(tot_imgs*0.8))\n",
    "for img_path in train_imgs:\n",
    "    img_name = img_path.split(\"/\")[-1]\n",
    "    xml_path = xml_directory + \"/\" + img_name.replace(\".jpg\", \".xml\")\n",
    "    copyfile(img_path, \"train/\" + img_name)\n",
    "    copyfile(xml_path, \"train/\" + img_name.replace(\".jpg\", \".xml\"))\n",
    "\n",
    "# Testing dataset\n",
    "test_imgs = [i for i in imgs if i not in train_imgs]\n",
    "for img_path in test_imgs:\n",
    "    img_name = img_path.split(\"/\")[-1]\n",
    "    xml_path = xml_directory + \"/\" + img_name.replace(\".jpg\", \".xml\")\n",
    "    copyfile(img_path, \"test/\" + img_name)\n",
    "    copyfile(xml_path, \"test/\" + img_name.replace(\".jpg\", \".xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(800),\n",
    "    transforms.ToTensor(),\n",
    "    utils.normalize_transform()\n",
    "])\n",
    "\n",
    "dataset = core.Dataset('train/', transform=custom_transforms)\n",
    "val_dataset = core.Dataset('test/', transform=custom_transforms)\n",
    "loader = core.DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "model = core.Model(['worker']) # Label of what we try to detect (same as value in xml file)\n",
    "losses = model.fit(loader, val_dataset, epochs=3, learning_rate=0.001, \n",
    "                   lr_step_size=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid training again, we can load the model directly here:\n",
    "model = core.Model.load('final_model.pth', [\"worker\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = glob.glob(\"train/*.jpg\")\n",
    "test_imgs = glob.glob(\"test/*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = random.choice(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbs(img_path, model, eps_proba=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot shows all the predicted bounding boxes (with eps higher than smth), while the second plot below shows only the predicted bounding boxes (with eps higher than smth) that we were able to match to a true bounding box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = plot_matching_bbs(img_path, model, eps_proba=0.1, eps_iou=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Green** boxes are the true bounding boxes. \\\n",
    "**Blue** boxes are the predicted ones. \\\n",
    "***Note:*** Among the predicted boxes, we only consider the boxes having an IOU higher than eps_iou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean IOU for this image is\", np.round(get_mean_iou(img_path, model, eps_proba=0.1, eps_iou=0), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ious_train = []\n",
    "for img_path in train_imgs:\n",
    "    iou = get_mean_iou(img_path, model, eps=0.1)\n",
    "    ious_train.append(iou)\n",
    "    print(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean IOU for training images is\", np.nanmean(ious_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for true box\n",
    "\n",
    "true_box = {}\n",
    "for img_path in train_imgs:\n",
    "    boxes = []\n",
    "    img_name = img_path.split(\"/\")[-1]\n",
    "    \n",
    "    xml_path = img_path.replace(\".jpg\", \".xml\")\n",
    "    with open(xml_path) as fd:\n",
    "        doc = xmltodict.parse(fd.read())\n",
    "        \n",
    "    try:\n",
    "        for i, obj in enumerate(doc[\"annotation\"][\"object\"]):\n",
    "            xmin = float(obj[\"bndbox\"][\"xmin\"])\n",
    "            xmax = float(obj[\"bndbox\"][\"xmax\"])\n",
    "            ymin = float(obj[\"bndbox\"][\"ymin\"])\n",
    "            ymax = float(obj[\"bndbox\"][\"ymax\"])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            \n",
    "    except KeyError: # When no object\n",
    "        pass\n",
    "    \n",
    "    except TypeError: # When only 1 object\n",
    "        xmin = float(doc[\"annotation\"][\"object\"][\"bndbox\"][\"xmin\"])\n",
    "        xmax = float(doc[\"annotation\"][\"object\"][\"bndbox\"][\"xmax\"])\n",
    "        ymin = float(doc[\"annotation\"][\"object\"][\"bndbox\"][\"ymin\"])\n",
    "        ymax = float(doc[\"annotation\"][\"object\"][\"bndbox\"][\"ymax\"])\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "    \n",
    "    true_box[img_name] = boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for pred box\n",
    "\n",
    "pred_box = {}\n",
    "for img_path in train_imgs:\n",
    "    img_name = img_path.split(\"/\")[-1]\n",
    "    pred_box[img_name] = {}\n",
    "    \n",
    "    image = utils.read_image(img_path)\n",
    "    labels, bbs, scores = model.predict(image)\n",
    "\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    for tensor, score in zip(bbs, scores):\n",
    "        xmin, ymin, xmax, ymax = tensor.numpy()\n",
    "        boxes_list.append([xmin, ymin, xmax, ymax])\n",
    "        scores_list.append(score.numpy().item())\n",
    "    \n",
    "    pred_box[img_name][\"boxes\"] = boxes_list\n",
    "    pred_box[img_name][\"scores\"] = scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(pred_box, open(\"dict_train.pkl\", \"wb\"))\n",
    "pred_box = pickle.load(open(\"dict_train.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall Curve\n",
    "\n",
    "iou_thr = 0.7\n",
    "start_time = time.time()\n",
    "data = get_avg_precision_at_iou(true_box, pred_box, iou_thr=iou_thr)\n",
    "end_time = time.time()\n",
    "print('Single IoU calculation took {:.4f} secs'.format(end_time - start_time))\n",
    "print('avg precision: {:.4f}'.format(data['avg_prec']))\n",
    "\n",
    "start_time = time.time()\n",
    "ax = None\n",
    "avg_precs = []\n",
    "iou_thrs = []\n",
    "for idx, iou_thr in enumerate(np.linspace(0.1, 0.9, 9)):\n",
    "    data = get_avg_precision_at_iou(true_box, pred_box, iou_thr=iou_thr)\n",
    "    avg_precs.append(data['avg_prec'])\n",
    "    iou_thrs.append(iou_thr)\n",
    "\n",
    "    precisions = data['precisions']\n",
    "    recalls = data['recalls']\n",
    "    ax = plot_pr_curve(\n",
    "        precisions, recalls, label='{:.2f}'.format(iou_thr), color=COLORS[idx], ax=ax)\n",
    "\n",
    "# Prettify\n",
    "avg_precs = [float('{:.4f}'.format(ap)) for ap in avg_precs]\n",
    "iou_thrs = [float('{:.4f}'.format(thr)) for thr in iou_thrs]\n",
    "print('map: {:.2f}'.format(100*np.mean(avg_precs)))\n",
    "print('avg precs: ', avg_precs)\n",
    "print('iou_thrs:  ', iou_thrs)\n",
    "plt.legend(loc='upper right', title='IOU Thr', frameon=True)\n",
    "for xval in np.linspace(0.0, 1.0, 11):\n",
    "    plt.vlines(xval, 0.0, 1.1, color='gray', alpha=0.3, linestyles='dashed')\n",
    "end_time = time.time()\n",
    "print('\\nPlotting and calculating mAP takes {:.4f} secs'.format(end_time - start_time))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
